{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: NumPy array Indexing/Slicing\n",
    "\n",
    "**Ex 1.1:** Load the \"iris.csv\" using the appropriate method for this file type (use the new functions from the package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal_length  sepal_width  petal_length  petal_width        class\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris_df = pd.read_csv(r'C:\\Users\\35191\\Documents\\GitHub\\si\\datasets\\iris\\iris.csv')\n",
    "print(iris_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 1.2:** Select the penultimate independent variable. What is the dimension of the resulting array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the resulting array: (150,)\n"
     ]
    }
   ],
   "source": [
    "penultimate_variable = iris_df.iloc[:, -2]\n",
    "print(\"Dimension of the resulting array:\", penultimate_variable.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 1.3:** Select the last 10 samples from the iris dataset. What is the mean of the last 10 samples for each\n",
    "independent variable/feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the last 10 samples for each independent variable/feature:\n",
      " sepal_length    6.45\n",
      "sepal_width     3.03\n",
      "petal_length    5.33\n",
      "petal_width     2.17\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "last10 = iris_df.iloc[-10:, :-1]\n",
    "mean_last10 = last10.mean()\n",
    "print(\"Mean of the last 10 samples for each independent variable/feature:\\n\", mean_last10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 1.4:** Select all samples from the dataset with values less than or equal to 6 for all independent variables/features. How many samples do you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with values less than or equal to 6 for all independent variables/features: 89\n"
     ]
    }
   ],
   "source": [
    "filtered_samples = iris_df[(iris_df.iloc[:, :-1] <= 6).all(axis=1)]\n",
    "num_samples = filtered_samples.shape[0]\n",
    "print(\"Number of samples with values less than or equal to 6 for all independent variables/features:\", num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 1.5:** Select all samples with a class/label different from 'Iris-setosa'. How many samples do you obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with a class/label different from 'Iris-setosa': 100\n"
     ]
    }
   ],
   "source": [
    "samples = iris_df[iris_df['class'] != 'Iris-setosa']\n",
    "num_samples = samples = iris_df[iris_df['class'] != 'Iris-setosa'].shape[0]\n",
    "print(\"Number of samples with a class/label different from 'Iris-setosa':\", num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 2:** \n",
    "\n",
    "Examples of how to use the fillna, dropna and remove_by_index methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from si.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "X: [[6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [nan 3.  5.6 nan]]\n",
      "y: ['Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "#Turning the iris dataset into a Dataset object and adding a row with NaN values\n",
    "X = last10.values\n",
    "new_row = np.array([np.nan, 3., 5.6, np.nan])\n",
    "X = np.vstack([X, new_row])\n",
    "y = iris_df.iloc[-10:, -1].values\n",
    "new_y = np.array(['Iris-setosa'])\n",
    "y = np.append(y, new_y)\n",
    "dataset = Dataset(X, y)\n",
    "\n",
    "print(\"Original Dataset:\")\n",
    "print(\"X:\", dataset.X)\n",
    "print(\"y:\", dataset.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains missing values.\n"
     ]
    }
   ],
   "source": [
    "if np.isnan(dataset.X).any() :\n",
    "    print(\"The dataset contains missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset copy: \n",
      " [[6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]\n",
      " [nan 3.  5.6 nan]]\n",
      "['Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-setosa']\n",
      "\n",
      " X after dropna:\n",
      " [[6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "y after dropna: ['Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "#Making a copy of the dataset\n",
    "X_copy = np.copy(dataset.X)\n",
    "y_copy = np.copy(dataset.y) \n",
    "dataset_copy = Dataset(X_copy, y_copy)\n",
    "\n",
    "print(\"Dataset copy: \\n\", dataset_copy.X)\n",
    "print(dataset_copy.y)\n",
    "\n",
    "# Removing samples with missing values using the dropna method\n",
    "cleaned_dataset = dataset_copy.dropna()\n",
    "print(\"\\n X after dropna:\\n\", cleaned_dataset.X)\n",
    "print(\"y after dropna:\", cleaned_dataset.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X after fillna:\n",
      " [[ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]\n",
      " [10.   3.   5.6 10. ]]\n",
      "y after fillna:\n",
      " ['Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "# Filling missing values with the mean of the corresponding feature using the fillna method\n",
    "filled_dataset = dataset.fillna(10.0)\n",
    "print(\"X after fillna:\\n\", filled_dataset.X)\n",
    "print(\"y after fillna:\\n\", filled_dataset.y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the modified dataset: (10, 4)\n",
      "X after remove_by_index:\n",
      " [[6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "y after remove_by_index:\n",
      " ['Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "# Removing the last sample using the remove_by_index method\n",
    "removed_dataset = filled_dataset.remove_by_index(-1)\n",
    "print(\"Size of the modified dataset:\", dataset.X.shape)\n",
    "print(\"X after remove_by_index:\\n\", removed_dataset.X)\n",
    "print(\"y after remove_by_index:\\n\", removed_dataset.y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 3:** Implementing SelectPercentile\n",
    "\n",
    "Testing the SelectPercentile class using the \"iris.csv\" dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from si.io.csv_file import read_csv\n",
    "from si.statistics.f_classification import f_classification\n",
    "from si.feature_selection.select_percentile import SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (150, 4)\n",
      "Transformed dataset shape: (150, 2)\n"
     ]
    }
   ],
   "source": [
    "iris_dataset = read_csv('../datasets/iris/iris.csv', features=True, label=True)\n",
    "\n",
    "# Create an instance of the SelectPercentile class\n",
    "selector = SelectPercentile(percentile=50)\n",
    "# Fit the selector to the dataset\n",
    "selector.fit(iris_dataset)\n",
    "\n",
    "# Transform the dataset using the fitted model\n",
    "transformed_dataset = selector.transform(iris_dataset)\n",
    "\n",
    "# Print the results\n",
    "print(\"Original dataset shape:\", iris_dataset.X.shape)\n",
    "print(\"Transformed dataset shape:\", transformed_dataset.X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F values: [ 119.26450218   47.3644614  1179.0343277   959.32440573]\n",
      "p values: [1.66966919e-31 1.32791652e-16 3.05197580e-91 4.37695696e-85]\n",
      "Original dataset shape: (150, 4)\n",
      "Transformed dataset shape: (150, 2)\n",
      "Original features:\n",
      " Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], dtype='object')\n",
      "Selected features:\n",
      " ['petal_width', 'petal_length']\n"
     ]
    }
   ],
   "source": [
    "selector2 = SelectPercentile()\n",
    "selector2.fit(iris_dataset)\n",
    "transformed_dataset2 = selector.transform(iris_dataset)\n",
    "\n",
    "print(\"F values:\", selector2.F)\n",
    "print(\"p values:\", selector2.p)\n",
    "\n",
    "print(\"Original dataset shape:\", iris_dataset.X.shape)\n",
    "print(\"Transformed dataset shape:\", transformed_dataset2.X.shape)\n",
    "print(\"Original features:\\n\", iris_dataset.features)\n",
    "print(\"Selected features:\\n\", transformed_dataset2.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercício 5:** PCA\n",
    "\n",
    "Testing the PCA class in a jupyter notebook using the iris.csv dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from si.decomposition.pca import PCA\n",
    "from sklearn.decomposition import PCA as PCA_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = read_csv('../datasets/iris/iris.csv', features=True, label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 2 components using PCA class\n",
    "np.random.seed(5)\n",
    "pca = PCA(n_components=2)\n",
    "pca._fit(iris_dataset.X)\n",
    "X_transformed = pca._transform(iris_dataset.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 2 components using PCA class from scikit-learn\n",
    "np.random.seed(5)\n",
    "pca_sklearn = PCA_sklearn(n_components=2)\n",
    "pca_sklearn.fit(iris_dataset.X)\n",
    "X_transformed_sklearn = pca_sklearn.transform(iris_dataset.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: [0.92461621 0.05301557]\n",
      "Explained variance by PCA from scikit-learn: [4.22484077 0.24224357]\n",
      "\n",
      "Transformed data structure: (150, 2)\n",
      "Transformed data structure by PCA from scikit-learn: (150, 2)\n",
      "\n",
      "First five lines of the Transformed data:\n",
      " [[-2.68420713 -0.32660731]\n",
      " [-2.71539062  0.16955685]\n",
      " [-2.88981954  0.13734561]\n",
      " [-2.7464372   0.31112432]\n",
      " [-2.72859298 -0.33392456]]\n",
      "First five lines of the Transformed data by PCA from scikit-learn:\n",
      " [[-2.68420713  0.32660731]\n",
      " [-2.71539062 -0.16955685]\n",
      " [-2.88981954 -0.13734561]\n",
      " [-2.7464372  -0.31112432]\n",
      " [-2.72859298  0.33392456]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained variance:\", pca.explained_variance)\n",
    "print(\"Explained variance by PCA from scikit-learn:\", pca_sklearn.explained_variance_)\n",
    "\n",
    "print(\"\\nTransformed data structure:\", X_transformed.shape)\n",
    "print(\"Transformed data structure by PCA from scikit-learn:\", X_transformed_sklearn.shape)\n",
    "\n",
    "print (\"\\nFirst five lines of the Transformed data:\\n\", X_transformed[:5])\n",
    "print(\"First five lines of the Transformed data by PCA from scikit-learn:\\n\", X_transformed_sklearn[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 2 components using PCA class and normalizing the data\n",
    "pca_norm = PCA(n_components=2)\n",
    "pca_norm._fit(iris_dataset.X, normalization=True)\n",
    "X_transformed_norm = pca_norm._transform(iris_dataset.X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA with 2 components using PCA class and normalizing the data using the StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "np.random.seed(5)\n",
    "X_scaled = StandardScaler().fit_transform(iris_dataset.X)\n",
    "pca_scaled = PCA(n_components=2)\n",
    "pca_scaled._fit(X_scaled)\n",
    "X_transformed_scaled = pca_scaled._transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance: [0.72770452 0.23030523]\n",
      "Explained variance using the StandardScaler: [0.72770452 0.23030523]\n",
      "\n",
      "Transformed data structure (normalized): (150, 2)\n",
      "Transformed data structure using the StandardScaler: (150, 2)\n",
      "\n",
      "First five lines of the Transformed data (normalized):\n",
      " [[-2.44159388 -0.02095745]\n",
      " [-2.41439075  0.51628447]\n",
      " [-2.62966145  0.40774632]\n",
      " [-2.53931232  0.53331485]\n",
      " [-2.52016653 -0.07628126]]\n",
      "First five lines of the Transformed data using the StandardScaler:\n",
      " [[-2.26454173 -0.5057039 ]\n",
      " [-2.0864255   0.65540473]\n",
      " [-2.36795045  0.31847731]\n",
      " [-2.30419716  0.57536771]\n",
      " [-2.38877749 -0.6747674 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Explained variance:\", pca_norm.explained_variance)\n",
    "print(\"Explained variance using the StandardScaler:\", pca_scaled.explained_variance)\n",
    "\n",
    "print(\"\\nTransformed data structure (normalized):\", X_transformed_norm.shape)\n",
    "print(\"Transformed data structure using the StandardScaler:\", X_transformed_scaled.shape)\n",
    "\n",
    "print (\"\\nFirst five lines of the Transformed data (normalized):\\n\", X_transformed_norm[:5])\n",
    "print(\"First five lines of the Transformed data using the StandardScaler:\\n\", X_transformed_scaled[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "si",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
